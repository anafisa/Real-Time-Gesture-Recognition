# Sign-Language-Classification
One of the main tasks of computer vision is image classification. Image classification involves predicting the class of one object in an image. 

Gesture recognition is rather challenging task as hands always are in motion, change angles and overlap each other, so the natural perception of hands in real time is a difficult task for computer vision.

The aim of this work is to create machine learning model that recognizes and classifies hand gestures in real time. To achieve this goal, it was necessary to solve a number of tasks:
1. Study and analyze existing approaches to the problem of gesture recognition;
2. Analyze and prepare initial data for training models;
3. Apply various methods of image classification to solve the problem;
4. Evaluate the quality and choose the best implemented model by metrics;
5. Conduct real-time sign language recognition experiments.

![demog](https://user-images.githubusercontent.com/30799388/146651464-fa939588-d9d3-402f-80df-daf430fe92c5.gif)

![short2](https://user-images.githubusercontent.com/30799388/146783843-aa67e5f0-e149-463c-b76b-33091e7cdca7.gif)

![short3](https://user-images.githubusercontent.com/30799388/146785561-7e557b46-e4cb-471f-af42-7fc842fff284.gif)
